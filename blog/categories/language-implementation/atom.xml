<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Language Implementation | Robert Mosolgo]]></title>
  <link href="http://rmosolgo.github.io/blog/categories/language-implementation/atom.xml" rel="self"/>
  <link href="http://rmosolgo.github.io/"/>
  <updated>2018-04-16T10:32:05-04:00</updated>
  <id>http://rmosolgo.github.io/</id>
  <author>
    <name><![CDATA[Robert Mosolgo]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Summer Reading: Specializing Ruby]]></title>
    <link href="http://rmosolgo.github.io/blog/2016/08/06/summer-reading-specializing-ruby/"/>
    <updated>2016-08-06T11:10:00-04:00</updated>
    <id>http://rmosolgo.github.io/blog/2016/08/06/summer-reading-specializing-ruby</id>
    <content type="html"><![CDATA[<p><a href="http://chrisseaton.com/phd/"><em>Specialising Dynamic Techniques for Implementing the Ruby Programming Language</em></a> (&ldquo;Specializing Ruby&rdquo;) is approachable and enjoyable (despite being a PhD thesis üòù).</p>

<!-- more -->


<p><em>Specializing Ruby</em> describes <a href="https://twitter.com/ChrisGSeaton">Chris Seaton</a>&rsquo;s work on <a href="http://chrisseaton.com/rubytruffle/">JRuby+Truffle</a>. It seems to be aimed at an unfamiliar audience, so it&rsquo;s loaded with background information and careful explanations. Those were a big benefit to me! I&rsquo;ll describe a few things that I enjoyed the most:</p>

<ul>
<li>Introduction to Truffle and Graal</li>
<li>Optimizing Metaprogramming with Dispatch Chains</li>
<li>Zero-Overhead Debugging</li>
<li>Interpreting Native Extensions</li>
</ul>


<h2>Introduction to Truffle and Graal</h2>

<p>Seaton&rsquo;s work is built on top of two existing Java projects: <strong>Truffle</strong> and <strong>Graal</strong> (pronunciation: üòñ‚ùì).</p>

<p>Truffle is a <em>language implementation framework</em> for <em>self-optimizing AST interpreters</em>. This means:</p>

<ul>
<li>Truffle is for <em>implementing languages</em>. People have used Truffle to implement many languages, including Ruby, C, and Python.</li>
<li>Truffle languages are <em>AST interpreters</em>. A Truffle language parses its source code into a tree of nodes (the <em>abstract syntax tree</em>, AST), which represents the program. Then, it executes the program by traversing the tree, taking actions at each node.</li>
<li>Truffle languages can <em>self-optimize</em>. Nodes can observe their execution and replace themselves with optimized versions of themselves.</li>
</ul>


<p>Graal is a <em>dynamic compiler</em> for the JVM, written in Java. A few points about Graal:</p>

<ul>
<li>It&rsquo;s a just-in-time compiler, so it improves a program&rsquo;s performance while the program runs.</li>
<li>Graal is written in Java, which means it can expose its own APIs to other Java programs (like Truffle).</li>
<li>Graal includes a powerful system for <em>de-optimizing</em>. This is especially important for Ruby, since Ruby&rsquo;s metaprogramming constructs allow programs to define new behavior for themselves while running.</li>
</ul>


<p>Truffle has a &ldquo;Graal backend,&rdquo; which supports close cooperation between the two. Together, they make a great team for language implementation: Truffle provides a simple approach to language design and Graal offers a means to optimize all the way to machine code.</p>

<h2>Optimizing Metaprogramming with Dispatch Chains</h2>

<p>This is a novel optimization technique for Ruby, described in section 5.</p>

<p>Since Ruby is dynamic, method lookups must happen at runtime. In CRuby, call sites have <em>caches</em> which store the result of method lookups and may short-circuit the lookup next time the call happens.</p>

<pre><code class="ruby">some_object.some_method(arg1, arg2)
#          ^- here's the call site
#             the _actual_ method definition to use
#             depends on `some_object`'s class, which is unknown
#             until the program is actually running
</code></pre>

<p>One such cache is a <em>polymorphic inline cache</em>, which is roughly a map of <code>Class =&gt; method</code> pairs. When CRuby starts the call, it checks the cache for the current receiver&rsquo;s class. On a cache hit, it uses the cached method definition. On a cache miss, it looks up a definition and adds it to the cache.</p>

<p>The cache might look like this:</p>

<pre><code class="ruby">some_object.some_method(arg1, arg2)
# Cache:
#   - SomeObject =&gt; SomeObject#some_method
#   - SomeOtherObject =&gt; SomeOtherObject#method_missing
</code></pre>

<p>In some cases, CRuby declares bankruptcy. Dynamic method calls (<code>.send</code>) are not cached!</p>

<pre><code class="ruby">some_object.send(method_name, arg1, arg2)
#          ^- who knows what method to call!?!?
</code></pre>

<p>JRuby+Truffle&rsquo;s solution to this challenge is <em>dispatch chains.</em> Each call site (including <code>.send</code>) gets a dispatch chain, which is a like two-layer cache. First, it stores the <em>name</em> of the method. Then, it stores the <em>class</em> of the receiver. For a &ldquo;static&rdquo; method call, it looks like this:</p>

<pre><code class="ruby">some_object.some_method(arg1, arg2)
# - "some_method" =&gt;
#    - SomeObject =&gt; SomeObject#some_method
#    - SomeOtherObject =&gt; SomeOtherObject#method_missing
</code></pre>

<p>And for a dynamic method call, it caches <em>each</em> method name:</p>

<pre><code class="ruby">some_object.send(method_name, arg1, arg2)
# - "some_method" =&gt;
#    - SomeObject =&gt; SomeObject#some_method
#    - SomeOtherObject =&gt; SomeOtherObject#method_missing
# - "some_other_method" =&gt;
#    - SomeObject =&gt; SomeObject#some_other_method
</code></pre>

<p>In this respect, JRuby+Truffle treats <em>every</em> method call like a <code>.send(...)</code>. This cache is implemented with Truffle nodes, so it&rsquo;s optimized as much as the rest of the program.</p>

<p>I wonder if this kind of method cache could be implemented for CRuby!</p>

<h2>Zero-Overhead Debugging</h2>

<p>Debugging in JRuby+Truffle (described in section 6) is a tour de force for the Truffle-Graal combo. Other Rubies incur big performance penalties for debugging. Some require a special &ldquo;debug&rdquo; flag. But Seaton implements zero-overhead, always-available debugging by applying Truffle concepts in a new way.</p>

<p>Debugging hooks (such as the beginning of a new line) are added as &ldquo;transparent&rdquo; Truffle AST nodes, analogous to CRuby&rsquo;s <code>trace</code> instruction. By default, they don&rsquo;t do anything &ndash; they just call through to their child nodes. Since they&rsquo;re &ldquo;just&rdquo; Truffle nodes, they&rsquo;re optimized like the rest of the program (and since they&rsquo;re transparent, they&rsquo;re optimized away completely). When those nodes are targeted for debugging, they&rsquo;re de-optimized, updated with the appropriate debug code, and the program continues running (and self-optimizing). When the debugger is detached, the node de-optimizes again, replaces itself with transparent nodes again, and the program resumes.</p>

<p>This chapter included a good description of Graal&rsquo;s <code>Assumption</code> concept. Assumptions are attached to optimized code. As long as <code>isValid()</code> is true, optimized code is executed. However, when an assumption is marked as invalid, Graal transfers execution back to the interpreter. Debugging takes advantage of this construct: debug nodes are transparent under the assumption that no debugger is attached to them. But when a developer attaches a debugger, then that assumption is invalidated and Graal de-optimizes and starts interpreting with the new debug nodes. Removing a debugger does the same thing: it invalidates an assumption, automatically de-optimizing the compiled code.</p>

<h2>Interpreting Native Extensions</h2>

<p>Truffle: if it&rsquo;s not solving your problems, you&rsquo;re not using enough of it!</p>

<p>Throughout the paper, Seaton points out the &ldquo;real-world&rdquo; challenge of any new Ruby implementation: it simply <em>must</em> support <em>all</em> existing code, including C extensions! If you require developers to rewrite code for a new implementation, they probably won&rsquo;t bother with it.</p>

<p>He also points out that CRuby&rsquo;s C API is an implementer&rsquo;s nightmare (my words, not his). It&rsquo;s tightly coupled to CRuby&rsquo;s implementation it provides direct access to CRuby&rsquo;s memory (eg, string pointers).</p>

<p>Truffle&rsquo;s design offers a solution to this problem. Truffle languages implement common interfaces for AST nodes and objects, meaning that they can be <em>shared</em> between languages! With this technique, JRuby+Truffle can implement Ruby&rsquo;s C API by interpreting C with Truffle. Since it&rsquo;s &ldquo;just Truffle&rdquo;, C and Ruby ASTs can be seamlessly merged. They are even optimized together, just like a pure-Ruby program.</p>

<p>Seaton describes some particular techniques for adapting the pre-existing TruffleC project to the Ruby C API. In typical fashion, JRuby+Truffle outpaces CRuby &ndash; even for C extensions!</p>

<h2>Conclusion</h2>

<p>The only remaining question I have is, how bad is warm-up cost in practice? All of JRuby+Truffle&rsquo;s benchmarks are at &ldquo;peak performance&rdquo;, but the system is &ldquo;cold&rdquo; at start-up, and many triggers in the program can cause the system to de-optimize. Is JIT warm-up a real issue?</p>

<p>&ldquo;Optimizing Ruby&rdquo; was a great read. Although I found the subject matter quite challenging, the writing style and occasional illustrations helped me keep up. Practically speaking, I can&rsquo;t use JRuby+Truffle until it runs all of Ruby on Rails, which isn&rsquo;t the case <em>yet</em>. I&rsquo;m eager to see how this project matures!</p>
]]></content>
  </entry>
  
</feed>
