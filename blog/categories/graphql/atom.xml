<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: GraphQL | Robert Mosolgo]]></title>
  <link href="http://rmosolgo.github.io/blog/categories/graphql/atom.xml" rel="self"/>
  <link href="http://rmosolgo.github.io/"/>
  <updated>2017-10-05T13:05:16-04:00</updated>
  <id>http://rmosolgo.github.io/</id>
  <author>
    <name><![CDATA[Robert Mosolgo]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Prototyping a GraphQL Schema From Definition With Ruby]]></title>
    <link href="http://rmosolgo.github.io/blog/2017/03/17/prototyping-a-graphql-schema-from-definition-with-ruby/"/>
    <updated>2017-03-17T15:49:00-04:00</updated>
    <id>http://rmosolgo.github.io/blog/2017/03/17/prototyping-a-graphql-schema-from-definition-with-ruby</id>
    <content type="html"><![CDATA[<p>GraphQL 1.5.0 includes a new way to define a schema: from a GraphQL definition.</p>

<!-- more -->


<p>In fact, loading a schema this way has been supported for while, but 1.5.0 adds the ability to specify field resolution behavior.</p>

<h2>GraphQL IDL</h2>

<p>Besides queries, GraphQL has an <em>interface definition language</em> (IDL) for expressing a schema’s structure. For example:</p>

<pre><code class="ruby">schema {
  query: Query
}

type Query {
  post(id: ID!): Post
}

type Post {
  title: String!
  comments: [Comment!]
}
</code></pre>

<p>You can turn a definition into a schema with <code>Schema.from_definition</code>:</p>

<pre><code class="ruby">schema_defn = "..."
schema = GraphQL::Schema.from_definition(schema_defn)
</code></pre>

<p>(By the way, the IDL is technically in <a href="https://github.com/facebook/graphql/pull/90">RFC stage</a>.)</p>

<h2>Resolvers</h2>

<p><code>Schema.from_definition</code> also accepts <code>default_resolve:</code> argument. It expects one of two inputs:</p>

<ul>
<li>A nested hash of type <code>Hash&lt;String =&gt; Hash&lt;String =&gt; #call(obj, args, ctx)&gt;&gt;</code>; or</li>
<li>An object that responds to <code>#call(type, field, obj, args, ctx)</code></li>
</ul>


<h4>Resolving with a Hash</h4>

<p>When you’re using a hash:</p>

<ul>
<li>The first key is a <em>type name</em></li>
<li>The second key is a <em>field name</em></li>
<li>The last value is a <em>resolve function</em> (<code>#call(obj, args, ctx)</code>)</li>
</ul>


<p>To get started, you can write the hash manually:</p>

<pre><code class="ruby">{
  "Query" =&gt; {
    "post" =&gt; -&gt;(obj, args, ctx) { Post.find(args[:id]) },
  },
  "Post" =&gt; {
    "title" =&gt; -&gt;(obj, args, ctx) { obj.title },
    "body" =&gt; -&gt;(obj, args, ctx) { obj.body },
    "comments" =&gt; -&gt;(obj, args, ctx) { obj.comments },
  },
}
</code></pre>

<p>But you can also reduce a lot of boilerplate by using a hash with default values:</p>

<pre><code class="ruby"># This hash will fall back to default implementation if another value isn't provided:
type_hash = Hash.new do |h, type_name|
  # Each type gets a hash of fields:
  h[type_name] = Hash.new do |h2, field_name|
    # Default resolve behavior is `obj.public_send(field_name, args, ctx)`
    h2[field_name] = -&gt;(obj, args, ctx) { obj.public_send(field_name, args, ctx) }
  end
end

type_hash["Query"]["post"] = -&gt;(obj, args, ctx) { Post.find(args[:id]) }

schema = GraphQL::Schema.from_definition(schema_defn, default_resolve: type_hash)
</code></pre>

<p>Isn’t that a nice way to set up a simple schema?</p>

<h4>Resolving with a Single Function</h4>

<p>You can provide a single callable that responds to <code>#call(type, field, obj, args, ctx)</code>. What a mouthful!</p>

<p>The <em>advantage</em> of that hefty method signature is that it’s enough to specify any resolution behavior you can imagine. For example, you could create a system where type modules were found by name, then methods were called by name:</p>

<pre><code class="ruby">module ExecuteGraphQLByConvention
  module_function
  # Find a Ruby module corresponding to `type`,
  # then call its method corresponding to `field`.
  def call(type, field, obj, args, ctx)
    type_module = Object.const_get(type.name)
    type_module.public_send(field.name, obj, args, ctx)
  end
end

schema = GraphQL::Schema.from_definition(schema_defn, default_resolve: ExecuteGraphQLByConvention)
</code></pre>

<p>So, a single function combined with Ruby’s flexibility and power opens a lot of doors!</p>

<p>Doesn’t it remind you a bit of method dispatch? The arguments are:</p>

<table>
<thead>
<tr>
<th>GraphQL Field Resolution </th>
<th> Method Dispatch</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>type</code> </td>
<td> class</td>
</tr>
<tr>
<td><code>field</code> </td>
<td> method</td>
</tr>
<tr>
<td><code>obj</code> </td>
<td> receiver</td>
</tr>
<tr>
<td><code>args</code> </td>
<td> method arguments</td>
</tr>
<tr>
<td><code>ctx</code> </td>
<td> runtime state (cf <a href="https://github.com/mruby/mruby/blob/master/include/mruby.h#L257"><code>mrb_state</code></a>, <a href="https://github.com/antirez/redis/blob/unstable/src/modules/INTRO.md"><code>RedisModuleCtx</code></a>, or <a href="http://erlang.org/doc/tutorial/nif.html"><code>ErlNifEnv</code></a>)</td>
</tr>
</tbody>
</table>


<h2>Special Configurations</h2>

<p>Some schemas need other configurations in order to run:</p>

<ul>
<li><code>resolve_type</code> to support union and interface types</li>
<li>schema plugins like <a href="https://rmosolgo.github.io/graphql-ruby/pro/monitoring">monitoring</a> or custom <a href="https://rmosolgo.github.io/graphql-ruby/schema/instrumentation">instrumentation</a></li>
</ul>


<p>To add these to a schema, use <code>.redefine</code>:
```ruby</p>

<h1>Extend the schema with new definitions:</h1>

<p>schema = schema.redefine {
  resolve_type ->(obj, ctx) { &hellip; }
  monitoring :appsignal
}
```</p>

<h2>What’s Next?</h2>

<p>Rails has proven that “Convention over Configuration” can be a very productive way to start new projects, so I’m interested in exploring convention-based APIs on top of this feature.</p>

<p>In the future, I’d like to add support for schema annotations in the form of directives, for example:</p>

<pre><code class="ruby">type Post {
  comments: [Comment!] @relation(hasMany: "comments")
}
</code></pre>

<p>These could be used to customize resolution behavior. Cool!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tracking Schema Changes with GraphQL-Ruby]]></title>
    <link href="http://rmosolgo.github.io/blog/2017/03/16/tracking-schema-changes-with-graphql-ruby/"/>
    <updated>2017-03-16T20:16:00-04:00</updated>
    <id>http://rmosolgo.github.io/blog/2017/03/16/tracking-schema-changes-with-graphql-ruby</id>
    <content type="html"><![CDATA[<p>One way to keep an eye on your GraphQL schema is to check the definition into source control.</p>

<!-- more -->


<p>When modifying shared code or reconfiguring, it can be hard to tell how the schema will <em>really</em> change. To help with this, set up a <strong>snapshot test</strong> for your GraphQL schema! This way:</p>

<ul>
<li>Changes will be clearly visible in GraphQL IDL</li>
<li>You can keep the IDL up-to-date by adding a test to your suite</li>
</ul>


<p>You can even track the schema from different contexts if you&rsquo;re using <a href="https://rmosolgo.github.io/graphql-ruby/pro/authorization"><code>GraphQL::Pro</code>&rsquo;s authorization framework</a>.</p>

<p>This approach was first described in <a href="https://www.youtube.com/watch?v=Wlu_PWCjc6Y">GraphQL at Shopify</a>.</p>

<h2>Check It In</h2>

<p>Write a <strong>Rake task</strong> to get your schema&rsquo;s definition and write it to a file:</p>

<pre><code class="ruby"># lib/tasks/graphql.rake
rake dump_schema: :environment do
  # Get a string containing the definition in GraphQL IDL:
  schema_defn = MyAppSchema.to_definition
  # Choose a place to write the schema dump:
  schema_path = "app/graphql/schema.graphql"
  # Write the schema dump to that file:
  File.write(Rails.root.join(schema_path), schema_defn)
  puts "Updated #{schema_path}"
end
</code></pre>

<p>You can run it from terminal:</p>

<pre><code class="sh">$ bundle exec rake dump_schema
Updated app/graphql/schema.graphql
</code></pre>

<p>This updates the file in your repo. Go ahead and <strong>check it in</strong>!</p>

<pre><code class="sh">$ git add app/graphql/schema.graphql
$ git commit -m "Add GraphQL schema dump"
</code></pre>

<h2>Keep It Up to Date</h2>

<p>Any changes to the Ruby schema code must be reflected in the <code>.graphql</code> file. You can give yourself a reminder by adding a <strong>test case</strong> which asserts that the GraphQL definition is up-to-date:</p>

<pre><code class="ruby"># test/graphql/my_app_schema_test.rb
require "test_helper"

class MyAppSchemaTest &lt; ActiveSupport::TestCase
  def test_printout_is_up_to_date
    current_defn = MyAppSchema.to_definition
    printout_defn = File.read(Rails.root.join("app/graphql/schema.graphql"))
    assert_equal(current_defn, printout_defn, "Update the printed schema with `bundle exec rake dump_schema`")
  end
end
</code></pre>

<p>If the definition is stale, you&rsquo;ll get a failed test:</p>

<p><img src="/images/tracking_schema/test_failure.png" width="500"></p>

<p>This reminder is helpful in development and <em>essential</em> during code review!</p>

<h2>Review It</h2>

<p>Now that your schema definition is versioned along with your code, you can see changes during <strong>code review</strong>:</p>

<p><img src="/images/tracking_schema/code_review.png" width="600"></p>

<h2>Multiple Schema Dumps</h2>

<p>If your schema looks different to different users, you can track <em>multiple</em> schema dumps. This is helpful if:</p>

<ul>
<li>You&rsquo;re using the <code>:view</code> configuration of <a href="https://rmosolgo.github.io/graphql-ruby/pro/authorization"><code>GraphQL::Pro</code>&rsquo;s authorization</a></li>
<li>You&rsquo;re using <code>only:</code>/ <code>except:</code> to manually filter your schema</li>
</ul>


<p>Just provide the <code>context:</code> argument to <code>Schema.to_definition</code> as if you were running a query. (Also provide <code>only:</code>/<code>except:</code> if you use them.)</p>

<p>Print with a filter from the Rake task:</p>

<pre><code class="ruby"># lib/tasks/graphql.rake
task dump_schema: :environment do
  # ...
  admin_user = OpenStruct.new(admin?: true)
  admin_schema_dump = MyAppSchema.to_definition(context: { current_user: admin_user })
  admin_schema_path = "app/graphql/admin_schema.graphql"
  File.write(Rails.root.join(admin_schema_path), admin_schema_dump)
end
</code></pre>

<p>Test with a filter from the test case:</p>

<pre><code class="ruby">def test_printout_is_up_to_date
  # ...
  admin_user = OpenStruct.new(admin?: true)
  current_admin_defn = MyAppSchema.to_definition(context: { current_user: admin_user })
  printout_admin_defn = File.read(Rails.root.join("app/graphql/admin_schema.graphql"))
  assert_equal(current_admin_defn, printout_admin_defn, "Update the printed schema with `bundle exec rake dump_schema`")
end
</code></pre>

<p>Now you can keep an eye on the schema from several perspectives!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Optimizing GraphQL-Ruby]]></title>
    <link href="http://rmosolgo.github.io/blog/2017/03/08/optimizing-graphql-ruby/"/>
    <updated>2017-03-08T08:02:00-05:00</updated>
    <id>http://rmosolgo.github.io/blog/2017/03/08/optimizing-graphql-ruby</id>
    <content type="html"><![CDATA[<p>Soon, <code>graphql-ruby</code> 1.5.0 will be released. Query execution will be ~70% faster than 1.3.0!</p>

<!-- more -->


<p>Let&rsquo;s look at how we reduced the execution time between those two versions. Thanks to <a href="https://github.com/theorygeek">@theorygeek</a> who optimized the middleware chain helped me pinpoint several other bottlenecks!</p>

<h2>The Benchmark</h2>

<p>To track GraphQL execution overhead, I <a href="https://github.com/rmosolgo/graphql-ruby/blob/master/benchmark/run.rb">execute the introspection query</a> on a <a href="https://github.com/rmosolgo/graphql-ruby/blob/master/spec/support/dummy/schema.rb">fixture schema</a> in graphql-ruby&rsquo;s test suite.</p>

<p>On GraphQL 1.3.0, the benchmark ran around 22.5 iterations per second:</p>

<p><img src="/images/optimizing_graphql_ruby/1-3-0-bench.png" width="500"></p>

<p>On <a href="https://github.com/rmosolgo/graphql-ruby/commit/943e68f40a11f3f809ecd8485282eccdd6a6991b">master</a>, it runs around 38 iterations per second:</p>

<p><img src="/images/optimizing_graphql_ruby/1-5-0-bench.png" width="500"></p>

<p>That&rsquo;s almost 1.7x faster!</p>

<pre><code class="ruby">38.0 / 22.5
# =&gt; 1.6888888888888889
</code></pre>

<p>So, how&rsquo;d we do it?</p>

<h2>Looking Under the Hood with RubyProf</h2>

<p>To find where time was spent, I turned to <a href="https://github.com/ruby-prof/ruby-prof">ruby-prof</a>. I <a href="https://github.com/rmosolgo/graphql-ruby/pull/579">wrapped GraphQL execution</a> with profiling and inspected the result:</p>

<pre><code class="text">Thread ID: 70149906635240
Fiber ID: 70149911114440
Total: 0.474618
Sort by: self_time

 %self      total      self      wait     child     calls  name
  4.60      0.074     0.022     0.000     0.052     6893  *Class#new
  3.99      0.019     0.019     0.000     0.000     8715  *GraphQL::Define::InstanceDefinable#ensure_defined
  3.13      0.015     0.015     0.000     0.000    25403   Module#===
  2.64      0.013     0.013     0.000     0.000     8813   Kernel#hash
  2.49      0.074     0.012     0.000     0.063     3496  *GraphQL::Schema::MiddlewareChain#call
  1.85      0.009     0.009     0.000     0.000     4184   GraphQL::Query::Context::FieldResolutionContext#query
  1.78      0.017     0.008     0.000     0.008     2141   #&lt;Module:0x007f9a18de37a8&gt;#type
  1.63      0.008     0.008     0.000     0.000     1960   GraphQL::Query::Context::FieldResolutionContext#initialize
  1.54      0.012     0.007     0.000     0.005     1748   GraphQL::Query#get_field
  1.53      0.014     0.007     0.000     0.006     1748   GraphQL::Query#arguments_for
  1.52      0.007     0.007     0.000     0.000     8356   Kernel#is_a?
  1.51      0.010     0.007     0.000     0.003     7523   Kernel#===
  1.44      0.022     0.007     0.000     0.015     1959   GraphQL::Query::Context::FieldResolutionContext#spawn
  1.32      0.012     0.006     0.000     0.006     1748   GraphQL::Execution::Lazy::LazyMethodMap#get
  1.31      0.010     0.006     0.000     0.003     1748   GraphQL::Execution::FieldResult#value=
  1.29      0.032     0.006     0.000     0.026     1748   GraphQL::Field#resolve
  1.25      0.042     0.006     0.000     0.037     1748   #&lt;Module:0x007f9a18de37a8&gt;#resolve
  1.16      0.015     0.006     0.000     0.010     1748   GraphQL::Execution::FieldResult#initialize
  1.06      0.010     0.005     0.000     0.005     2815   GraphQL::Schema::Warden#visible?
  1.05      0.014     0.005     0.000     0.009     1748   GraphQL::Schema::MiddlewareChain#initialize
  1.03      0.005     0.005     0.000     0.000     2815   &lt;Module::GraphQL::Query::NullExcept&gt;#call
  0.97      0.014     0.005     0.000     0.009      756   Hash#each_value
# ... truncated ...
</code></pre>

<p>A few things stood out:</p>

<ul>
<li>~5% of time was spent during ~7k calls to <code>Class#new</code>: this is time spent initializing new objects. I think initialization can also trigger garbage collection (if there&rsquo;s not a spot on the free list), so this may include GC time.</li>
<li>~4% of time was spent during ~9k calls to <code>InstanceDefinable#ensure_defined</code>, which is part of graphql-ruby&rsquo;s definition API. It&rsquo;s <em>all</em> overhead to support the definition API, 😿.</li>
<li>Several methods are called <code>1748</code> times. Turns out, this is <em>once per field in the response</em>.</li>
<li>With that in mind, <code>25,403</code> seems like a lot of calls to <code>Module#===</code>!</li>
</ul>


<h2>Reduce GC Pressure</h2>

<p>Since <code>Class#new</code> was the call with the most <code>self</code> time, I thought I&rsquo;d start there. What kind of objects are being allocated? We can filter the profile output:</p>

<pre><code class="text">~/code/graphql $ cat 130_prof.txt | grep initialize
  1.63      0.008     0.008     0.000     0.000     1960   GraphQL::Query::Context::FieldResolutionContext#initialize
  1.16      0.015     0.006     0.000     0.010     1748   GraphQL::Execution::FieldResult#initialize
  1.05      0.014     0.005     0.000     0.009     1748   GraphQL::Schema::MiddlewareChain#initialize
  0.69      0.006     0.003     0.000     0.002     1833   Kernel#initialize_dup
  0.46      0.002     0.002     0.000     0.000     1768   Array#initialize_copy
  0.30      0.001     0.001     0.000     0.000      419   GraphQL::Execution::SelectionResult#initialize
  0.28      0.001     0.001     0.000     0.000      466   Hash#initialize
  0.17      0.010     0.001     0.000     0.009       92   GraphQL::InternalRepresentation::Selection#initialize
  0.15      0.002     0.001     0.000     0.001      162   Set#initialize
  0.15      0.001     0.001     0.000     0.000       70   GraphQL::InternalRepresentation::Node#initialize
  0.07      0.001     0.000     0.000     0.001       58   GraphQL::StaticValidation::FieldsWillMerge::FieldDefinitionComparison#initialize
  0.04      0.001     0.000     0.000     0.000       64   GraphQL::Query::Arguments#initialize
  0.01      0.000     0.000     0.000     0.000       11   GraphQL::StaticValidation::FragmentsAreUsed::FragmentInstance#initialize
  0.01      0.000     0.000     0.000     0.000        1   GraphQL::Query#initialize
# ... truncated ...
</code></pre>

<p>Lots of GraphQL internals! That&rsquo;s good news though: those are within scope for optimization.</p>

<p><code>MiddlewareChain</code> was ripe for a refactor. In the old implementation, <em>each</em> field resolution created a middleware chain, then used it and discarded it. However, this was a waste of objects. Middlewares don&rsquo;t change during query execution, so we should be able to reuse the same list of middlewares for each field.</p>

<p>This required a bit of refactoring, since the old implementation modified the array (with <code>shift</code>) as it worked through middlewares. In the end, this improvement was added in <a href="https://github.com/rmosolgo/graphql-ruby/pull/462/commits/5549e0cff288a9aecd676603cbb62628a34b4ec8"><code>5549e0cf</code></a>. As a bonus, the number of created <code>Array</code>s (shown by <code>Array#initialize_copy</code>) also declined tremendously since they were used for <code>MiddlewareChain</code>&rsquo;s internal state. Also, calls to <code>Array#shift</code> were removed, since the array was no longer modified:</p>

<pre><code class="text">~/code/graphql $ cat 130_prof.txt | grep shift
  0.61      0.003     0.003     0.000     0.000     3496   Array#shift
~/code/graphql $ cat 150_prof.txt | grep shift
~/code/graphql $
</code></pre>

<p>🎉 !</p>

<p>The number <code>FieldResult</code> objects was also reduced. <code>FieldResult</code> is used for execution bookkeeping in some edge cases, but is often unneeded. So, we could optimize by removing the <code>FieldResult</code> object when we had a plain value (and therefore no bookkeeping was needed): <a href="https://github.com/rmosolgo/graphql-ruby/commit/07cbfa89031819d3886f220de8256e83ff59f298"><code>07cbfa89</code></a></p>

<p>A very modest optimization was also applied to <code>GraphQL::Arguments</code>, reusing the same object for empty argument lists (<a href="https://github.com/rmosolgo/graphql-ruby/pull/500/commits/4b07c9b46345144c7d88e429e7b55e09b0615517"><code>4b07c9b4</code></a>) and reusing the argument default values on a field-level basis (<a href="https://github.com/rmosolgo/graphql-ruby/pull/500/commits/4956149df0a4ab8a449679bcd9af20b3dad72585"><code>4956149d</code></a>).</p>

<h2>Avoid Duplicate Calculations</h2>

<p>Some elements of a GraphQL schema don&rsquo;t change during execution. As long as this holds true, we can cache the results of some calculations and avoid recalculating them.</p>

<p>A simple caching approach is to use a hash whose keys are the inputs and whose values are the cached outputs:</p>

<pre><code class="ruby"># Read-through cache for summing two numbers
#
# The first layer of the cache is the left-hand number:
read_through_sum = Hash.new do |hash1, left_num|
  # The second layer of the cache is the right-hand number:
  hash1[num1] = Hash.new do |hash2, right_num|

    # And finally, the result is stored as a value in the second hash:
    puts "Adding #{left_num} + #{right_num}"
    hash2[right_num] = left_num + right_num
  end
end

read_through_sum[1][2]
# "Adding 1 + 2"
# =&gt; 3

read_through_sum[1][2]
# =&gt; 3
</code></pre>

<p>The first lookup printed a message and returned a value but the second lookup did <em>not</em> print a value. This is because the block wasn&rsquo;t called. Instead, the cached value was returned immediately.</p>

<p>This approach was applied aggressively to <code>GraphQL::Schema::Warden</code>, an object which manages schema visibility on a query-by-query basis. Since the visibility of a schema member would remain constant during the query, we could cache the results of visibility checks: first <a href="https://github.com/rmosolgo/graphql-ruby/pull/462/commits/1a28b10494bf508519f8f9b4a1a589c458837cf7"><code>1a28b104</code></a>, then <a href="https://github.com/rmosolgo/graphql-ruby/pull/462/commits/27b36e89ca24b1dc8ec3e2d27612a6fb99039e54"><code>27b36e89</code></a>.</p>

<p>This was also applied to field lookup in <a href="https://github.com/rmosolgo/graphql-ruby/pull/402/commits/133ed1b1e0577df1db222a892d8afd95082c6d33"><code>133ed1b1e</code></a> and to <code>lazy_resolve</code> handler lookup in <a href="https://github.com/rmosolgo/graphql-ruby/pull/402/commits/283fc19d72eb9890ea6254f7fc79600f3f0bfbeb"><code>283fc19d</code></a>.</p>

<h2>Use <code>yield</code> Instead of <code>&amp;block</code></h2>

<p>Due to the implementation of Ruby&rsquo;s VM, calling a block with <a href="https://github.com/JuanitoFatas/fast-ruby#proccall-and-block-arguments-vs-yieldcode"><code>yield</code> is much faster than <code>block.call</code></a>. <code>@theorygeek</code> migrated <code>MiddlewareChain</code> to use that approach instead in <a href="https://github.com/rmosolgo/graphql-ruby/pull/462/commits/517cec3477097ddb05db0e02b6752be552d2e3dd"><code>517cec34</code></a>.</p>

<h2>Remove Overhead from Lazy Definition API (warning: terrible hack)</h2>

<p>In order to handle circular definitions, graphql-ruby&rsquo;s <code>.define { ... }</code> blocks aren&rsquo;t executed immediately. Instead, they&rsquo;re stored and evaluated only when a definition-dependent value is required. To achieve this, all definition-dependent methods were preceeded by a call to <code>ensure_defined</code>.</p>

<p>Maybe you remember that method from the <em>very top</em> of the profiler output above:</p>

<pre><code class="text"> %self      total      self      wait     child     calls  name
  4.60      0.074     0.022     0.000     0.052     6893  *Class#new
  3.99      0.019     0.019     0.000     0.000     8715  *GraphQL::Define::InstanceDefinable#ensure_defined
</code></pre>

<p>A fact about <code>GraphQL::Schema</code> is that, by the time it is defined, <em>all</em> lazy definitions have been executed. This means that during query execution, calling <code>ensure_defined</code> is <em>always</em> a waste!</p>

<p>I found a way to remove the overhead, but it was a huge hack. It works like this:</p>

<p>When a definition is added (with <code>.define</code>):</p>

<ul>
<li>store the definition block for later</li>
<li><p>find each definition-dependent method definition on the defined object and gather them into an array:</p>

<pre><code class="ruby">@pending_methods = method_names.map { |n| self.class.instance_method(n) }
</code></pre></li>
<li><em>replace</em> those methods with dummy methods which:

<ul>
<li>call <code>ensure_defined</code></li>
<li>re-apply all <code>@pending_methods</code>, overriding the dummy methods</li>
<li>call the <em>real</em> method (which was just re-applied)</li>
</ul>
</li>
</ul>


<p>This way, subsequent calls to definition-dependent methods <em>don&rsquo;t</em> call <code>ensure_defined</code>. <code>ensure_defined</code> removed itself from the class definition after its work was done!</p>

<p>You can see the whole hack in <a href="https://github.com/rmosolgo/graphql-ruby/pull/483/commits/18d73a58314cab96c28a9861506b6ad18c8df3aa"><code>18d73a58</code></a>. For all my teasing, this is something that makes Ruby so powerful: if you can imagine it, you can code it!</p>

<h2>The Final Product</h2>

<p>Two minor releases later, the profile output is looking better! Here&rsquo;s the output on master:</p>

<pre><code class="text">Thread ID: 70178713115080
Fiber ID: 70178720382840
Total: 0.310395
Sort by: self_time

 %self      total      self      wait     child     calls  name
  4.06      0.013     0.013     0.000     0.000     7644   Kernel#hash
  2.93      0.021     0.009     0.000     0.012     2917  *Class#new
  2.89      0.009     0.009     0.000     0.000     4184   GraphQL::Query::Context::FieldResolutionContext#query
  2.74      0.009     0.009     0.000     0.000    13542   Module#===
  2.60      0.008     0.008     0.000     0.000     1960   GraphQL::Query::Context::FieldResolutionContext#initialize
  2.27      0.013     0.007     0.000     0.006     1748   GraphQL::Query#arguments_for
  2.25      0.010     0.007     0.000     0.003     7523   Kernel#===
  2.14      0.022     0.007     0.000     0.015     1959   GraphQL::Query::Context::FieldResolutionContext#spawn
  2.09      0.007     0.007     0.000     0.000     8260   Kernel#is_a?
  1.87      0.039     0.006     0.000     0.033     1748   GraphQL::Schema::RescueMiddleware#call
  1.75      0.013     0.005     0.000     0.008     1748   GraphQL::Execution::Lazy::LazyMethodMap#get
  1.69      0.005     0.005     0.000     0.000     2259   Kernel#class
  1.68      0.044     0.005     0.000     0.039     3496  *GraphQL::Schema::MiddlewareChain#invoke_core
  1.33      0.004     0.004     0.000     0.000     1747   GraphQL::Query::Context::FieldResolutionContext#schema
  1.31      0.029     0.004     0.000     0.025     1748   &lt;Module::GraphQL::Execution::Execute::FieldResolveStep&gt;#call
  1.20      0.004     0.004     0.000     0.000     1748   GraphQL::Execution::SelectionResult#set
  1.15      0.048     0.004     0.000     0.044     1748   GraphQL::Schema::MiddlewareChain#invoke
  1.14      0.017     0.004     0.000     0.013     1748   GraphQL::Schema#lazy_method_name
  1.07      0.004     0.003     0.000     0.001     1044   Kernel#public_send
  1.05      0.020     0.003     0.000     0.017     1748   GraphQL::Schema#lazy?
  1.02      0.004     0.003     0.000     0.000     1806   GraphQL::InternalRepresentation::Node#definition
</code></pre>

<p>Here are the wins:</p>

<ul>
<li>Object allocations reduced by 58%</li>
<li>Method calls to gem code and Ruby built-ins reduced by &hellip; a lot!</li>
<li>Calls to <code>ensure_defined</code> reduced by 100% 😆</li>
</ul>


<p>And, as shown in the benchmark above, 1.7x faster query execution!</p>

<p>There&rsquo;s one caveat: these optimization apply to the GraphQL runtime <em>only</em>. <em>Real</em> GraphQL performance depends on more than that. It includes application-specific details like database access, remote API calls and application code performance.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Persisted GraphQL Queries with Ruby]]></title>
    <link href="http://rmosolgo.github.io/blog/2017/03/07/persisted-graphql-queries-with-ruby/"/>
    <updated>2017-03-07T07:55:00-05:00</updated>
    <id>http://rmosolgo.github.io/blog/2017/03/07/persisted-graphql-queries-with-ruby</id>
    <content type="html"><![CDATA[<p><a href="http://graphql.pro" target="_blank">GraphQL Pro</a> 1.3.0 adds <a href="http://rmosolgo.github.io/graphql-ruby/pro/persisted_queries">support for server-defined queries via <code>GraphQL::Pro::Repository</code></a>. In this approach, GraphQL operations are stored on the server and clients invoke them by name.</p>

<!-- more -->


<p>This provides several benefits:</p>

<ul>
<li>You can completely close the door to client-provided query strings. This removes an attack vector for a malicious client who might try to swamp your system with expensive queries.</li>
<li>Static queries (in <code>.graphql</code> files) are easier to review and more available tooling (eg, code generation or analysis).</li>
<li>Operation names improve <a href="http://rmosolgo.github.io/graphql-ruby/pro/monitoring">GraphQL server monitoring</a> by serving as the primary unit of analysis.</li>
</ul>


<h2>What&rsquo;s a &ldquo;repository?&rdquo;</h2>

<p>A <code>GraphQL::Pro::Repository</code> works like a single, large GraphQL document with many different operations (ie, queries, mutations, or subscriptions) and fragments inside it. These operations are validated and analyzed as a single unit, as if they came in a single query string.</p>

<p>From a client&rsquo;s perspective, the server has a fixed set of operations it can perform. Each one can be executed by sending its <a href="http://graphql.org/learn/queries/#operation-name">operation name</a>.</p>

<p>The repository approach allows us to use pre-existing GraphQL concepts:</p>

<ul>
<li><strong><a href="https://facebook.github.io/graphql/#sec-Language.Query-Document">Document</a></strong>: A GraphQL document is a set of operations and fragments. The semantics of a valid document are <a href="https://facebook.github.io/graphql/#sec-Validation">well-specified</a> and broadly implemented. A repository is an extension of this concept.</li>
<li><a href="http://graphql.org/learn/queries/#operation-name"><strong>Operation name</strong></a>: GraphQL includes a way to specify which operation to run in a document. Repositories build on this by separating the set of operations (which lives on the server) from the identifier (which comes from the client).</li>
</ul>


<p>By employing these concepts, we make full use of the battle-tested <a href="https://github.com/rmosolgo/graphql-ruby">graphql-ruby</a> runtime without deviating from the spec.</p>

<h2>A Quick Example</h2>

<p>First, add a <code>.graphql</code> file with a named operation:</p>

<pre><code># app/graphql/documents/GetItems.graphql
query GetItems {
  # Your GraphQL here:
  items {
    name
  }
}
</code></pre>

<p>Then, define a repository with that path:</p>

<pre><code class="ruby">MyAppRepository = GraphQL::Pro::Repository.define do
  schema MyAppSchema
  path Rails.root.join("app/graphql/documents")
end
</code></pre>

<p>Next, update your controller to execute queries with the repository instead of the schema:</p>

<pre><code class="diff"># app/controllers/graphql_controller.rb
- MyAppSchema.execute(
-   query_string,
+ MyAppRepository.execute(
+   operation_name: params[:operationName]
    context: context,
    variables: variables,
  )
</code></pre>

<p>Finally, execute the operation by sending a request with the <code>operationName</code>:</p>

<pre><code class="js">$.post("/graphql", { operationName: "GetItems" }, function(response) {
  console.log(response.data)
})

// {
//   items: [
//     { name: "Item 1" },
//     ...
//    ]
// }
</code></pre>

<p>🎉 We served a GraphQL response by name!</p>

<h2>Naming Files</h2>

<p>A straightforward approach is to name <code>.graphql</code> files after the operations they contain, so this operation:</p>

<pre><code class="text">mutation UpdateComment($id: Int!, $body: String!) {
  updateComment(id: $id, body: $body) {
    # ...
  }
}
</code></pre>

<p>would go in:</p>

<pre><code>app/graphql/documents/UpdateComment.graphql
</code></pre>

<p>This way, a reader can skim the <code>app/graphql/documents</code> directory to take a quick inventory of operations. Also, this one-to-one mapping mimics the Ruby convention of putting constants in identically-named files.</p>

<p>In the end, <code>GraphQL::Pro::Repository</code> will accept files with any name, as long as they match <code>#{path}/**/*.graphql</code>.</p>

<h2>Sharing Fragments</h2>

<p>Since a repository functions as one big GraphQL document, <a href="http://graphql.org/learn/queries/#fragments">fragments</a> are shared by default.</p>

<p>You can put fragments in their own files, then reference them from each operation that needs them. This way, operations with common data responsibilities can share code, ensuring that they stay in sync.</p>

<p>For example, consider a list of comments with a box to create a new comment. We&rsquo;d make three <code>.graphql</code> files:</p>

<pre><code class="text">app/graphql/documents/
  ListComments.graphql
  CreateComment.graphql
  CommentFields.graphql
</code></pre>

<p>First, specify the operation to load the list of comments:</p>

<pre><code class="text"># app/graphql/documents/ListComments.graphql
query ListComments($postId: ID!) {
  post(id: $id) {
    comments {
      author {
        name
      }
      body
      createdAt
      updatedAt
    }
  }
}
</code></pre>

<p>Then, specify the operation to create a new comment:</p>

<pre><code class="text"># app/graphql/documents/CreateComment.graphql
query CreateComment($postId: ID!, $body: String!) {
  createComment(postId: $postId, body: $body) {
    # ??
  }
}
</code></pre>

<p>After creating a comment, you want to update the list of comments to include the new member. To express this shared need for data, create a fragment with the required fields:</p>

<pre><code class="text"># app/graphql/documents/CommentFields.graphql
fragment CommentFields on Comment {
  author {
    name
  }
  body
  createdAt
  updatedAt
}
</code></pre>

<p>Then, apply the fragment to <code>ListComments</code> and <code>CreateComment</code>:</p>

<pre><code class="diff"># app/graphql/documents/ListComments.graphql
  query ListComments($postId: ID!) {
    post(id: $id) {
      comments {
+       ...CommentFields
-       author {
-         name
-       }
-       body
-       createdAt
-       updatedAt
      }
    }
  }
</code></pre>

<pre><code class="diff">  # app/graphql/documents/CreateComment.graphql
  query CreateComment($postId: ID!, $body: String!) {
    createComment(postId: $postId, body: $body) {
-     # ??
+     ...CommentFields
    }
  }
</code></pre>

<p>This way:</p>

<ul>
<li>A reader can see that these operations are linked</li>
<li>If the list view ever requires more data, the create operation will load that data, too</li>
</ul>


<h2>Next Steps</h2>

<ul>
<li>Repositories can also <a href="http://rmosolgo.github.io/graphql-ruby/pro/persisted_queries#arbitrary-input">accept dynamic inputs</a>. This allows you to use GraphiQL during development or continue serving old clients while you transition to server-defined queries.</li>
<li>On Rails, repositories watch their files and reload as needed. If you&rsquo;re using another framework, you can <a href="http://rmosolgo.github.io/graphql-ruby/pro/persisted_queries#watching-files">reload repositories</a> as needed.</li>
<li>You can use a repository to find <a href="http://rmosolgo.github.io/graphql-ruby/pro/persisted_queries#analysis">unused fields</a> in your schema.</li>
</ul>


<p>For me, I&rsquo;m hoping to improve client support (eg, Apollo Client) and server tooling (eg, query diffing) to make repositories even more useful!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parallelism in GraphQL-Ruby]]></title>
    <link href="http://rmosolgo.github.io/blog/2017/01/22/parallelism-in-graphql-ruby/"/>
    <updated>2017-01-22T10:23:00-05:00</updated>
    <id>http://rmosolgo.github.io/blog/2017/01/22/parallelism-in-graphql-ruby</id>
    <content type="html"><![CDATA[<p>It&rsquo;s possible to get IO operations running in parallel with the <a href="https://github.com/rmosolgo/graphql-ruby"><code>graphql</code> gem</a>.</p>

<!-- more -->


<p>I haven&rsquo;t tried this extensively, but I had to satisfy my curiosity!</p>

<h2>Setup: Long-Running IO</h2>

<p>Let&rsquo;s say we have a GraphQL schema which has long-running IO- or system-bound tasks. Here&rsquo;s a silly example where the long-running task is <code>sleep</code>:</p>

<pre><code class="ruby">QueryType = GraphQL::ObjectType.define do
  name "Query"
  field :sleep, !types.Int, "Sleep for the specified number of seconds" do
    argument :for, !types.Int
    resolve -&gt;(o, a, c) {
      sleep(a["for"])
      a["for"]
    }
  end
end

Schema = GraphQL::Schema.define do
  query(QueryType)
end
</code></pre>

<p>Let&rsquo;s consider a query like this one:</p>

<pre><code>query_str = &lt;&lt;-GRAPHQL
{
  s1: sleep(for: 3)
  s2: sleep(for: 3)
  s3: sleep(for: 3)
}
GRAPHQL

puts query_str

puts Benchmark.measure {
  Schema.execute(query_str)
}
</code></pre>

<p>How long will it take?</p>

<pre><code>$ ruby graphql_parallel.rb
{
  s1: sleep(for: 3)
  s2: sleep(for: 3)
  s3: sleep(for: 3)
}
  0.000000   0.000000   0.000000 (  9.009428)
</code></pre>

<p>About 9 seconds: three <code>sleep(3)</code> calls in a row.</p>

<h2>Working in Another Thread</h2>

<p>The <a href="https://github.com/ruby-concurrency/concurrent-ruby"><code>concurrent-ruby</code> gem</a> includes <code>Concurrent::Future</code>, which runs a block in another thread:</p>

<pre><code class="ruby">future = Concurrent::Future.execute do
  # This will be run in another thread
end


future.value
# =&gt; waits for the return value of the block
#    and returns it
</code></pre>

<p>We can use it to put our <code>sleep(3)</code> calls in different threads. There are two steps.</p>

<p>First, use a <code>Concurrent::Future</code> in the resolve function:</p>

<pre><code class="diff">- sleep(a["for"])
- a["for"]
+ Concurrent::Future.execute {
+  sleep(a["for"])
+  a["for"]
+ }
</code></pre>

<p>Then, tell the Schema to handle <code>Concurrent::Future</code>s by calling <code>#value</code> on them:</p>

<pre><code class="diff"> Schema = GraphQL::Schema.define do
   query(QueryType)
+  lazy_resolve(Concurrent::Future, :value)
 end
</code></pre>

<p>Finally, run the same query again:</p>

<pre><code>$ ruby graphql_parallel.rb
{
  s1: sleep(for: 3)
  s2: sleep(for: 3)
  s3: sleep(for: 3)
}
  0.000000   0.000000   0.010000 (  3.011735)
</code></pre>

<p>🎉 Three seconds! Since the <code>sleep(3)</code> calls were in different threads, they were executed in parallel.</p>

<h2>Real Uses</h2>

<p>Ruby can run IO operations in parallel. This includes filesystem operations and socket reads (eg, HTTP requests and database operations).</p>

<p>So, you could make external requests inside a <code>Concurrent::Future</code>, for example:</p>

<pre><code class="ruby">Concurrent::Future.execute {
  open("http://wikipedia.org")
}
</code></pre>

<p>Or, make a long-running database call inside a <code>Concurrent::Future</code>:</p>

<pre><code class="ruby">Concurrent::Future.execute {
  DB.exec(long_running_sql_query)
}
</code></pre>

<h2>Caveats</h2>

<p>Switching threads incurs some overhead, so multithreading won&rsquo;t be worth it for very fast IO operations.</p>

<p>GraphQL doesn&rsquo;t know which resolvers will finish first. Instead, it starts each one, then blocks until the first one is finished. This means that subsequent long-running fields may have to wait longer than they &ldquo;really&rdquo; need to. For example, consider this query:</p>

<pre><code>{
  sleep(for: 5)
  nestedSleep(for: 2) {
    sleep(for: 2)
  }
}
</code></pre>

<p>Even with multithreading, this would take about 7 seconds to execute. First, GraphQL would wait for <code>sleep(for: 5)</code>, then it would get to <code>nestedSleep(for: 2)</code>, which would have already finished, then it would execute <code>sleep(for: 2)</code>.</p>

<h2>Conclusion</h2>

<p>If your GraphQL schema is wrapping pre-existing HTTP APIs, using a technique like this could reduce your GraphQL response time.</p>
]]></content>
  </entry>
  
</feed>
